{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CGpmhOf83qTJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D,BatchNormalization, Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DHwG1hbqejCp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39795, 192, 112, 1)\n",
            "(39795, 45, 1)\n"
          ]
        }
      ],
      "source": [
        "with h5py.File(os.getcwd() + '/data/dataset_itop.hdf5', 'r') as hf:\n",
        "    x_train = np.asarray(hf['x_train'])\n",
        "    y_train = np.asarray(hf['y_train'])\n",
        "    x_test  = np.asarray(hf['x_test'])\n",
        "    y_test  = np.asarray(hf['y_test'])\n",
        "    \n",
        "train_size, img_w, img_h = x_train.shape\n",
        "test_size, j_type, j_coord = y_test.shape\n",
        "\n",
        "x_train = np.reshape(x_train, (train_size, img_w, img_h, 1))\n",
        "x_test  = np.reshape(x_test,  (test_size,  img_w, img_h, 1))\n",
        "\n",
        "y_train = np.reshape(y_train, (train_size, j_type*j_coord, 1))\n",
        "y_test  = np.reshape(y_test,  (test_size,  j_type*j_coord, 1))\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WEl8MgIZ314L"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001     #@param {type:\"raw\"}\n",
        "num_epochs_to_train = 10  #@param {type:\"integer\"}\n",
        "batch_size = 64           #@param {type:\"integer\"}\n",
        "vector_dimension = 256    #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gQrs3mzERfuT"
      },
      "outputs": [],
      "source": [
        "def calculate_reconstruction_loss(y_target, y_predicted):\n",
        "    error = y_target - y_predicted\n",
        "    reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])\n",
        "    return reconstruction_loss\n",
        "\n",
        "\n",
        "def calculate_kl_loss(model):\n",
        "    def _calculate_kl_loss(*args):\n",
        "        kl_loss = -0.5 * K.sum(1 + model.log_variance - K.square(model.mu) -\n",
        "                               K.exp(model.log_variance), axis=1)\n",
        "        return kl_loss\n",
        "    return _calculate_kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CA22vi-e33MU"
      },
      "outputs": [],
      "source": [
        "class VAE:\n",
        "  def __init__(self,\n",
        "               input_shape, #shape of the input data\n",
        "               conv_filters, #convolutional network filters\n",
        "               conv_kernels, #convNet kernel size\n",
        "               conv_strides, #convNet strides\n",
        "               latent_space_dim):\n",
        "    self.input_shape = input_shape # (192, 112)\n",
        "    self.conv_filters = conv_filters # is a list for each layer, i.e. [2, 4, 8]\n",
        "    self.conv_kernels = conv_kernels # list of kernels per layer, [1, 2, 3]\n",
        "    self.conv_strides = conv_strides # stride for each filter [1, 2, 2], note: 2 means you are downsampling the data in half\n",
        "    self.latent_space_dim = latent_space_dim # how many neurons on bottleneck\n",
        "    self.reconstruction_loss_weight = 100000\n",
        "\n",
        "    self.encoder = None\n",
        "    self.decoder = None\n",
        "    self.model = None\n",
        "    self.hist = None\n",
        "\n",
        "    self._num_conv_layers = len(conv_filters)\n",
        "    self._shape_before_bottleneck = None\n",
        "    self._model_output = None\n",
        "    self._model_input = None\n",
        "    self._foi_input = None\n",
        "\n",
        "    self._build()\n",
        "\n",
        "  def summary(self):\n",
        "    self.encoder.summary()\n",
        "    print(\"\\n\")\n",
        "    self.decoder.summary()\n",
        "    print(\"\\n\")\n",
        "    self.model.summary()\n",
        "\n",
        "  def _build(self):\n",
        "    self._build_encoder()\n",
        "    self._build_decoder()\n",
        "    self._build_autoencoder()\n",
        "\n",
        "  def compile(self, learning_rate=0.0001):\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    self.model.compile(optimizer=optimizer, loss=self._calculate_combined_loss,\n",
        "                       metrics=[calculate_reconstruction_loss, calculate_kl_loss(self)])\n",
        "  \n",
        "  \n",
        "  def train(self, x_train, batch_size, num_epochs):\n",
        "    self.hist = self.model.fit(x_train, x_train,\n",
        "                               batch_size=batch_size,\n",
        "                               epochs=num_epochs,\n",
        "                               shuffle=True)\n",
        "    \n",
        "  def _calculate_combined_loss(self, y_target, y_predicted):\n",
        "    reconstruction_loss = calculate_reconstruction_loss(y_target, y_predicted)\n",
        "    kl_loss = calculate_kl_loss(self)()\n",
        "    combined_loss = self.reconstruction_loss_weight * reconstruction_loss + kl_loss\n",
        "    return combined_loss\n",
        "\n",
        "  #----------------FULL MODEL-----------------#\n",
        "  def _build_autoencoder(self):\n",
        "    model_input = self._model_input\n",
        "    model_output = self.decoder(self.encoder(model_input))\n",
        "    self.model = Model(model_input, model_output, name='autoencoder')\n",
        "\n",
        "  #----------------DECODER-----------------#\n",
        "  def _build_decoder(self):\n",
        "    decoder_input = self._add_decoder_input()\n",
        "    dense_layer = self._add_dense_layer(decoder_input)\n",
        "    reshape_layer = self._add_reshape_layer(dense_layer)\n",
        "    conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
        "    decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
        "    self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "    self._model_output = self.decoder(self.encoder(self._model_input))\n",
        "    \n",
        "\n",
        "  def _add_decoder_input(self):\n",
        "    return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
        "\n",
        "  def _add_dense_layer(self, decoder_input):\n",
        "    num_neurons = np.prod(self._shape_before_bottleneck) # [ 1, 2, 4] -> 8\n",
        "    dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
        "    return dense_layer\n",
        "\n",
        "  def _add_reshape_layer(self, dense_layer):\n",
        "    return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
        "\n",
        "  def _add_conv_transpose_layers(self, x):\n",
        "    for layer_index in reversed(range(1, self._num_conv_layers)):\n",
        "      x = self._add_conv_transpose_layer(layer_index, x)\n",
        "    return x\n",
        "\n",
        "  def _add_conv_transpose_layer(self, layer_index, x):\n",
        "    layer_num = self._num_conv_layers - layer_index\n",
        "    conv_transpose_layer = Conv2DTranspose(\n",
        "        filters=self.conv_filters[layer_index],\n",
        "        kernel_size = self.conv_kernels[layer_index],\n",
        "        strides = self.conv_strides[layer_index],\n",
        "        activation='relu',\n",
        "        padding = \"same\",\n",
        "        name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
        "    )\n",
        "    x = conv_transpose_layer(x)\n",
        "    x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
        "    return x\n",
        "\n",
        "  def _add_decoder_output(self, x):\n",
        "    conv_transpose_layer = Conv2DTranspose(\n",
        "        filters = 1,\n",
        "        kernel_size = self.conv_kernels[0],\n",
        "        strides = self.conv_strides[0],\n",
        "        padding = \"same\",\n",
        "        name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
        "    )\n",
        "    x = conv_transpose_layer(x)\n",
        "    output_layer = Activation(\"sigmoid\", name=\"sigmoid_output_layer\")(x)\n",
        "    return output_layer\n",
        "\n",
        "  #----------------ENCODER-----------------#\n",
        "  def _build_encoder(self):\n",
        "    encoder_input = self._add_encoder_input()\n",
        "    conv_layers = self._add_conv_layers(encoder_input)\n",
        "    bottleneck =  self._add_bottleneck(conv_layers)\n",
        "    self._model_input = encoder_input\n",
        "    self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
        "\n",
        "  def _add_encoder_input(self):\n",
        "    return Input(shape=self.input_shape, name=\"encoder_input\")\n",
        "\n",
        "  def _add_conv_layers(self, encoder_input):\n",
        "    \"\"\"Creates all convolutional blocks in encoder\"\"\"\n",
        "    x = encoder_input\n",
        "    for layer_index in range(self._num_conv_layers):\n",
        "      x = self._add_conv_layer(layer_index, x)\n",
        "    return x\n",
        "  \n",
        "  def _add_conv_layer(self, layer_index, x):\n",
        "    \"\"\"\n",
        "    Adds a convolutional block to a graph of layers, consisting\n",
        "    of Conv 2d + ReLu activation + batch normalization.\n",
        "    \"\"\"\n",
        "    layer_number = layer_index + 1\n",
        "    conv_layer = Conv2D(\n",
        "        filters= self.conv_filters[layer_index],\n",
        "        kernel_size = self.conv_kernels[layer_index],\n",
        "        strides = self.conv_strides[layer_index],\n",
        "        activation='relu',\n",
        "        padding = \"same\",\n",
        "        name = f\"encoder_conv_layer_{layer_number}\"\n",
        "    )\n",
        "    x = conv_layer(x)\n",
        "    x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
        "    return x\n",
        "\n",
        "  #-------------LATTENT SPACE-------------#\n",
        "  def _add_bottleneck(self, x):\n",
        "    \"\"\"Flatten data and add bottleneck with Gaussian sampling (Dense layer)\"\"\"\n",
        "    self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
        "    x = Flatten()(x)\n",
        "    self.mu = Dense(self.latent_space_dim,name=\"mu\")(x)\n",
        "    self.log_variance = Dense(self.latent_space_dim,\n",
        "                              name=\"log_variance\")(x)\n",
        "    \n",
        "    def sample_point_from_normal_distribution(args):\n",
        "      mu, log_variance = args\n",
        "      epsilon = K.random_normal(shape=K.shape(self.mu), mean=0., stddev=1.)\n",
        "      sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
        "\n",
        "      return sampled_point\n",
        "\n",
        "    x = Lambda(sample_point_from_normal_distribution, \n",
        "              name=\"encoder_output\")([self.mu, self.log_variance])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWX2PvXk34zB"
      },
      "outputs": [],
      "source": [
        "vae = VAE(input_shape = (192, 112, 1), \n",
        "          conv_filters=(128, 64, 32, 16), \n",
        "          conv_kernels=(3, 3, 3, 3), \n",
        "          conv_strides=(2, 2, 2, (2,1)), \n",
        "          latent_space_dim = vector_dimension\n",
        "          )\n",
        "\n",
        "# vae.encoder.summary()\n",
        "# vae.decoder.summary()\n",
        "print(vae.model.count_params())\n",
        "# tf.keras.utils.plot_model(vae.model, expand_nested=True, show_shapes=True)\n",
        "\n",
        "vae.compile(learning_rate)\n",
        "vae.train(x_train, batch_size, num_epochs_to_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNmYHGpI1u49"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(vae.model, expand_nested=True, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_j5N9-Nl0hv"
      },
      "outputs": [],
      "source": [
        "loss = vae.hist.history['loss']\n",
        "# val_loss = vae.hist.history['val_loss']\n",
        "\n",
        "epochs = range(num_epochs_to_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIfXdVn1ZbJ0"
      },
      "outputs": [],
      "source": [
        "depth_img_pred = vae.model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B78cA2eZwBj"
      },
      "outputs": [],
      "source": [
        "plt.matshow(depth_img_pred[501], cmap=plt.cm.viridis, interpolation='bicubic')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.grid(visible=None)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25mGhGmfX5Ni"
      },
      "outputs": [],
      "source": [
        "plt.matshow(x_test[501], cmap=plt.cm.viridis, interpolation='bicubic')\n",
        "plt.colorbar()\n",
        "\n",
        "plt.grid(visible=None)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
